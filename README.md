# Big Data Course Resources

Welcome to the repository for the Big Data Course. 

This repository contains practical exercises and resources intended for educational purposes. Below is an overview of the contents and objectives of the course.

## ğŸ“š Course Focus
The course focuses on utilizing Hadoop and PySpark to:

- Understand the fundamentals of Big Data processing.
- Develop skills in handling and analyzing large datasets.
- Implement data processing pipelines and perform distributed computing tasks.

## ğŸ“ Datasets
The exercises include working with:

- Simulated datasets to understand basic concepts and practice data processing techniques.
- Real-world datasets obtained from open repositories, specifically those related to Catalonia.

These datasets provide a diverse range of data types and structures, allowing students to gain hands-on experience with both structured and unstructured data.

## ğŸ“œ Contents
1. Introduction to Hadoop and PySpark:
Learn the basics of Hadoop and PySpark, setting up the environment, and understanding the architecture.

2. Data Ingestion and Storage:
Techniques for ingesting data into Hadoop and storing it in HDFS.

3. Data Processing with PySpark:
Writing and optimizing PySpark jobs to process large datasets.

4. Data Analysis and Visualization:
Using PySpark for data analysis and generating insights from large data volumes.

5. Case Studies and Real-World Applications:
Applying learned techniques to real-world scenarios using datasets from Spain, Catalonia.

This course is offered by **Eurecat Academy**.
